{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4526,
     "status": "ok",
     "timestamp": 1760370303627,
     "user": {
      "displayName": "Gopika K",
      "userId": "13586043768047292832"
     },
     "user_tz": -330
    },
    "id": "mjJs2IjvPpAY"
   },
   "outputs": [],
   "source": [
    "# Implement problems on Natural Language processing - Part of Speech tagging, N-grams and Chunking using NLTK.\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ngrams, RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1760371153907,
     "user": {
      "displayName": "Gopika K",
      "userId": "13586043768047292832"
     },
     "user_tz": -330
    },
    "id": "ZEQU5gILP1vI",
    "outputId": "cf2da145-8b75-450c-d33f-2f141ab95cfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15860,
     "status": "ok",
     "timestamp": 1760371512171,
     "user": {
      "displayName": "Gopika K",
      "userId": "13586043768047292832"
     },
     "user_tz": -330
    },
    "id": "yM2-byF9P9I4",
    "outputId": "932f9d94-a406-4942-9742-f87ed07e4258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence: Hello my name is Chotta Bheem\n",
      "\n",
      "Part of Speech Tags:\n",
      "\n",
      "Hello           --> NNP\n",
      "my              --> PRP$\n",
      "name            --> NN\n",
      "is              --> VBZ\n",
      "Chotta          --> NNP\n",
      "Bheem           --> NNP\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Take user input ---\n",
    "sentence = input(\"Enter a sentence: \")\n",
    "# --- Step 2: Tokenize the sentence ---\n",
    "tokens = word_tokenize(sentence)\n",
    "# --- Step 3: POS tagging ---\n",
    "tags = pos_tag(tokens)\n",
    "# --- Step 4: Display POS tagging results ---\n",
    "print(\"\\nPart of Speech Tags:\\n\")\n",
    "for word, tag in tags:\n",
    "  print(f\"{word:15} --> {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7646,
     "status": "ok",
     "timestamp": 1760371531083,
     "user": {
      "displayName": "Gopika K",
      "userId": "13586043768047292832"
     },
     "user_tz": -330
    },
    "id": "gGVcwaeUSNfZ",
    "outputId": "143c91c8-a93c-43be-9170-695f12a6c9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter n for n-grams (e.g., 2 for bigrams, 3 for trigrams): 2\n",
      "\n",
      "2-grams:\n",
      "\n",
      "('Hello', 'my')\n",
      "('my', 'name')\n",
      "('name', 'is')\n",
      "('is', 'Chotta')\n",
      "('Chotta', 'Bheem')\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: N-gram generation ---\n",
    "n = int(input(\"\\nEnter n for n-grams (e.g., 2 for bigrams, 3 for trigrams): \"))\n",
    "ngram_list = list(ngrams(tokens, n))\n",
    "print(f\"\\n{n}-grams:\\n\")\n",
    "for gram in ngram_list:\n",
    "  print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1760371539048,
     "user": {
      "displayName": "Gopika K",
      "userId": "13586043768047292832"
     },
     "user_tz": -330
    },
    "id": "Jrz5GZ61UQXf",
    "outputId": "3ce55fc5-6b8b-434f-b5b4-8b21d64120b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunked Phrases:\n",
      "\n",
      "(S\n",
      "  (NP Hello/NNP)\n",
      "  my/PRP$\n",
      "  (NP name/NN)\n",
      "  (VP is/VBZ (NP Chotta/NNP) (NP Bheem/NNP)))\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Define a simple chunk grammar ---\n",
    "# Grammar rules:\n",
    "# NP = Noun Phrase, VP = Verb Phrase, PP = Prepositional Phrase\n",
    "grammar = r\"\"\"\n",
    "NP: {<DT>?<JJ>*<NN.*>} # Noun Phrase\n",
    "VP: {<VB.*><NP|PP|CLAUSE>+$} # Verb Phrase\n",
    "PP: {<IN><NP>} # Prepositional Phrase\n",
    "\"\"\"\n",
    "# --- Step 7: Create a chunk parser ---\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "# --- Step 8: Parse the tagged sentence ---\n",
    "tree = chunk_parser.parse(tags)\n",
    "# --- Step 9: Display the chunk tree ---\n",
    "print(\"\\nChunked Phrases:\\n\")\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmwMTvZWDnF6ZEFKrdD0Dk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
